{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3553691b",
   "metadata": {},
   "source": [
    "# Real Analysis Homework 9\n",
    "\n",
    "Isaac Hawn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec5be6a",
   "metadata": {},
   "source": [
    "$\\textbf{1)}$ \n",
    "\n",
    "We want to prove that if $f$ is integrable on $\\mathbb{R}$, then:\n",
    "\n",
    "$$\n",
    "\\lim_{n\\to\\infty} \\int_\\mathbb{R} f(x) \\cos(nx)dx = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad262924",
   "metadata": {},
   "source": [
    "First we must prove the lemma $\\int_\\mathbb{R} |\\psi(x) \\cos(nx)|dx \\to 0$ for some step function $\\psi$.\n",
    "\n",
    "Proof:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba201f8a",
   "metadata": {},
   "source": [
    "Let $\\psi$ be a step function and let $I = \\bigcup \\{x:\\psi(x)\\neq 0\\}$. So now we can restrict the domain and only consider the integral over $I$. As a step function, we can treat $\\psi$ as a constant to get $\\int_I |\\psi(x) \\cos(nx)|dx = k\\int_I |\\cos(nx)|dx$ for some constant $k$. Therfore, we consider only the integral $\\int_I |\\cos(nx)|dx$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea21399",
   "metadata": {},
   "source": [
    "We see the following:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\int_I |\\cos(nx)|dx &= \\text{sign}(\\cos(nx))\\int_I \\cos(nx)dx \\\\\n",
    "&= \\frac{|\\cos(nx)|}{\\cos(nx)} \\int_I \\cos(nx)dx \\\\\n",
    "&= \\frac{\\sin(nx)|\\cos(nx)|}{n\\cos(nx)} \\Bigg|_I\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27442b98",
   "metadata": {},
   "source": [
    "We see $\\lim_{n\\to\\infty} \\frac{\\sin(nx)|\\cos(nx)|}{n\\cos(nx)} = 0$ implying $\\int_\\mathbb{R} |\\psi(x) \\cos(nx)|dx \\to 0$. $\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba2cb34",
   "metadata": {},
   "source": [
    "Proof of original statement:\n",
    "\n",
    "Let $f$ be a function, integrable over $\\mathbb{R}$. By problem 15 on page 94, we may pick a step function $\\psi$ such that $\\int_\\mathbb{R}|f-\\psi| < \\epsilon$. Let $\\psi = \\sum_{k} b_k \\chi_{E_k}$ be such a step function approximating $f$ with step heights $b_k$ and step intervals $E_k$. We see that $\\left|\\int_\\mathbb{R} f(x) \\cos(nx)dx\\right| \\leq \\left|\\int_\\mathbb{R} \\psi(x) \\cos(nx)dx\\right| + \\int_\\mathbb{R}|f(x) - \\psi(x)| dx$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ca3a27",
   "metadata": {},
   "source": [
    "For a function $h$, we have that $\\left|\\int h\\right| \\leq \\int|h|$. Thus $\\left|\\int_\\mathbb{R} \\psi(x) \\cos(nx)dx\\right|\\leq \\int_\\mathbb{R} |\\psi(x) \\cos(nx)|dx$. By the lemma, this integral goes to zero as $n\\to\\infty$. Also, $\\int_\\mathbb{R}|f(x) - \\psi(x)| dx < \\epsilon$ since $\\psi$ approximates $f$. Therefore, $\\left|\\int_\\mathbb{R} f(x) \\cos(nx)dx - 0\\right| < \\epsilon + \\epsilon = 2\\epsilon$ for $n$ large enough meaning that $\\lim_{n\\to\\infty} \\int_\\mathbb{R} f(x) \\cos(nx)dx = 0$. $\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615e4cd",
   "metadata": {},
   "source": [
    "$\\textbf{2)}$\n",
    "\n",
    "We want to show that the set $E_\\infty = \\{x\\in(a,b): (D_- f)(x) = \\infty\\}$ has measure zero.\n",
    "\n",
    "Proof:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e6fea",
   "metadata": {},
   "source": [
    "Let $E_k = \\{x\\in(a,b): (D_- f)(x) > k\\}$ for $k > 0$. Notice that $E_\\infty = \\bigcap E_k$. Let $\\mathcal{F}$ represent all closed subintervals $J = [z_n, z_{n+1}]$ such that $J\\subset(a,b)$ and $f(z_{n+1}) - f(z_n)\\geq m^*(J)p$ for some $p\\in(0,k)$. The collection $\\mathcal{F}$ forms a Vitali cover of $E_k$ since $D_- f \\geq p$ over $E_k$. By Vitali's Covering Lemma, there is a finite disjoint collection $\\{I_1,\\ldots,I_N\\}$ of intervals covering $E_k$ such that $m^*\\left(E_k\\backslash\\bigcup_{n=1}^N I_n\\right) <\\epsilon$ and since each $I_n$ is disjoint, $m^*\\left(\\bigcup_{n=1}^N I_n\\right) = \\sum_{n=1}^N m^*(I_n)$ implying $m^*(E_k)<\\epsilon+\\sum_{n=1}^N m^*(I_n)$. Let $x_{n_1}$ and $x_{n_2}$ be the left and right endpoints respectively for each $I_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef3df29",
   "metadata": {},
   "source": [
    " We have $f(z_{n+1}) - f(z_n)\\geq m^*(J)p\\to \\frac1p(f(z_{n+1}) - f(z_n))\\geq m^*(J)$ so subadditivity gives us $\\epsilon+\\sum_{n=1}^N m^*(I_n) \\leq \\epsilon + \\frac1p\\sum_{n=1}^N(f(x_{n_2}) - f(x_{n_1}))$. The original theorem on page 100 states that $f$ is increasing over $(a,b)$ so we must have $\\epsilon + \\frac1p\\sum_{n=1}^N(f(x_{n_2}) - f(x_{n_1}) \\leq \\epsilon+\\frac1p(f(b)-f(a))$. Thus $m^*(E_k) < \\epsilon + \\frac1p(f(b)-f(a))$. As $k\\to\\infty$, we may pick values of $p$ that go to infinity so $\\epsilon + \\frac1p(f(b)-f(a))$ may be as small as we want. Therefore, $m^*(E_k) = 0$ implying $m(E_\\infty)=0$ since $E_\\infty = \\bigcap E_k$. $\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5635efb6",
   "metadata": {},
   "source": [
    "$\\textbf{3)}$\n",
    "\n",
    "For $mE<\\infty$ and measurable functions $h$ and $g$ defined on $E$, we define:\n",
    "\n",
    "$$\n",
    "\\rho(g, h) = \\int_E \\frac{|g-h|}{1+|g-h|}\n",
    "$$\n",
    "\n",
    "We want to prove that $\\rho$ is a metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20271fb3",
   "metadata": {},
   "source": [
    "Proof that $\\rho(g,h) = 0$ if and only if $g = h$ a.e:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4382cd5d",
   "metadata": {},
   "source": [
    "Suppose $g = h$ a.e for measurable functions $g$ and $h$. Then $\\int_E \\frac{|g-h|}{1+|g-h|} = \\int_E \\frac01 = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9fe4a6",
   "metadata": {},
   "source": [
    "Conversely suppose $\\rho(g, h) = 0$ so we have $\\int_E \\frac{|g-h|}{1+|g-h|} = 0$. Differentiating yields $\\frac{|g-h|}{1+|g-h|} = 0$ so $|g-h| = 0$ meaingin $g = h$ a.e. $\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201845b",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4391e43",
   "metadata": {},
   "source": [
    "Proof that $\\rho(g,h) = \\rho(h,g)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d00614a",
   "metadata": {},
   "source": [
    "We have that $\\int_E \\frac{|g-h|}{1+|g-h|} = \\int_E \\frac{|h-g|}{1+|h-g|}$ trivially since $|h-g| = |g-h|$. $\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df81e23d",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92e8bd",
   "metadata": {},
   "source": [
    "Proof that $\\rho(f,h)\\leq\\rho(f,g) + \\rho(g,h)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85b0a3",
   "metadata": {},
   "source": [
    "Let $f$, $g$, and $h$ be measurable functions defined on $E$. Clearly $\\hat{\\rho}(g,h) = |g-h|$ is a metric so $|f-g|+|g-h| \\geq |f-h|$. Thus, $\\frac{|f-g|}{1+|f-g|} + \\frac{|g-h|}{1+|g-h|} \\geq \\frac{|f-h|}{1+|f-h|}$ implying:\n",
    "\n",
    "$$\n",
    "\\rho(f,g) + \\rho(g,h) = \\int_E \\frac{|f-g|}{1+|f-g|} + \\int_E \\frac{|g-h|}{1+|g-h|} \\geq\\int_E \\frac{|f-h|}{1+|f-h|} = \\rho(f,h).\n",
    "\\;\\blacksquare$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31015ff8",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e86b191",
   "metadata": {},
   "source": [
    "Now we want to prove that $f_n\\to f$ in measure on $E$ if and only if $\\lim_{n\\to\\infty}\\rho(f_n, f) = 0$.\n",
    "\n",
    "Proof:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4d6b62",
   "metadata": {},
   "source": [
    "Suppose $f_n\\to f$ in measure. Let $I = \\{x:|f_n(x) - f(x)|\\geq \\epsilon\\}$ for $\\epsilon > 0$. We have $\\rho(f_n, f) = \\int_I \\frac{|f_n-f|}{1+|f_n-f|} + \\int_{E\\backslash I} \\frac{|f_n-f|}{1+|f_n-f|}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f901c15",
   "metadata": {},
   "source": [
    "By definition, $mI < \\epsilon$ so $\\int_I \\frac{|f_n-f|}{1+|f_n-f|}\\to 0$ as $n\\to\\infty$. Further, we have that $|f_n-f| < \\epsilon$ over the set $E\\backslash I$. Thus, $|f_n-f|\\to 0$ as $n\\to\\infty$ on $E\\backslash I$ implying $\\int_{E\\backslash I} \\frac{|f_n-f|}{1+|f_n-f|}\\to 0$ as $n\\to\\infty$. Therefore $\\lim_{n\\to\\infty}\\rho(f_n, f) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f74f40",
   "metadata": {},
   "source": [
    "Conversely, suppose $\\lim_{n\\to\\infty}\\rho(f_n, f) = 0$. Let set $I$ be as before. We have that $\\rho(f_n, f) = \\int_I \\frac{|f_n-f|}{1+|f_n-f|} + \\int_{E\\backslash I} \\frac{|f_n-f|}{1+|f_n-f|}$ so both integrals must go to zero. This means that $\\int_I \\frac{|f_n-f|}{1+|f_n-f|}$ goes to zero and since $|f_n - f| \\geq \\epsilon$ over $I$ we will have that $\\frac{|f_n-f|}{1+|f_n-f|}>0$ strictly. Thus,  $\\int_I \\frac{|f_n-f|}{1+|f_n-f|}$ may only go to zero if $mI\\to 0$ as $n\\to\\infty$ implying $mI<\\epsilon$ i.e. $f_n\\to f$ in measure.\n",
    "\n",
    "Therefore, $f_n\\to f$ in measure on $E$ if and only if $\\lim_{n\\to\\infty}\\rho(f_n, f) = 0$. $\\blacksquare$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
